<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Publications - Jinwoo Kim</title>
  <meta name="author" content="Jinwoo Kim">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <style>
    body {
      max-width: 620px;
      margin: 20px auto;
      padding: 0 20px;
      background-color: #fdf6e3;
    }
  </style>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Z80P1GGMNH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-Z80P1GGMNH');
  </script>
</head>

<body>

  <h1>Publications</h1>

  <p><a href="index.html">back</a></p>

  <p>*: equal contribution, <sup>&dagger;</sup>: equal advising</p>

  <p>
    Architecture-Agnostic Invariances for Deep Learning<br>
    <u>Jinwoo Kim</u><br>
    Ph.D. Dissertation, 2026. <b>KAIST CoE Best Dissertation Award</b><br>
    [<a href="https://drive.google.com/file/d/1kowZhLcFB7w4poHj2xb48UZ-D_VdyjQC/view?usp=drive_link">pdf</a>]
  </p>

  <p>
    Inverting Data Transformations via Diffusion Sampling<br>
    <u>Jinwoo Kim</u>*, Sékou-Oumar Kaba*, Jiyun Park, Seunghoon Hong<sup>&dagger;</sup>, Siamak
    Ravanbakhsh<sup>&dagger;</sup><br>
    Under review, 2026
  </p>

  <p>
    Flock: A Knowledge Graph Foundation Model via Learning on Random Walks<br>
    <u>Jinwoo Kim</u>*, Xingyue Huang*, Krzysztof Olejniczak, Kyungbin Min, Michael Bronstein, Seunghoon Hong, İsmail
    İlkan
    Ceylan<br>
    ICLR, 2026<br>
    [<a href="https://arxiv.org/abs/2510.01510">paper</a>] [<a href="https://github.com/jw9730/flock-pytorch">code</a>]
  </p>

  <p>
    Sequence Modeling with Spectral Mean Flows<br>
    <u>Jinwoo Kim</u>, Max Beier, Petar Bevanda, Nayun Kim, Seunghoon Hong<br>
    NeurIPS, 2025<br>
    [<a href="https://arxiv.org/abs/2510.15366">paper</a>] [<a
      href="https://github.com/jw9730/spectral-mean-flow">code</a>]
  </p>

  <p>
    Revisiting Random Walks for Learning on Graphs<br>
    <u>Jinwoo Kim</u>, Olga Zaghen*, Ayhan Suleymanzade*, Youngmin Ryou, Seunghoon Hong<br>
    ICLR, 2025. <b>Spotlight (380/11672=3.26%)</b><br>
    ICML GRaM Workshop, 2024. ELLIS Mobility Grant<br>
    [<a href="https://arxiv.org/abs/2407.01214">paper</a>] [<a href="https://github.com/jw9730/random-walk">code</a>]
    [<a href="https://drive.google.com/file/d/16Xqs1afU-o6UqcLyNBs1zfHb3lfsKUSO/view?usp=sharing">poster</a>]
  </p>

  <p>
    3D Denoisers are Good 2D Teachers: Molecular Pretraining via Denoising and Cross-Modal Distillation<br>
    Sungjun Cho, Dae-Woong Jeong, Sung Moon Ko, <u>Jinwoo Kim</u>, Sehui Han, Seunghoon Hong, Honglak Lee, Moontae
    Lee<br>
    AAAI, 2025. <b>Oral</b><br>
    [<a href="https://arxiv.org/abs/2309.04062">paper</a>]
  </p>

  <p>
    Simulation-Free Training of Neural ODEs on Paired Data<br>
    Semin Kim*, Jaehoon Yoo*, <u>Jinwoo Kim</u>, Yeonwoo Cha, Saehoon Kim, Seunghoon Hong<br>
    NeurIPS, 2024<br>
    [<a href="https://arxiv.org/abs/2410.22918">paper</a>] [<a
      href="https://github.com/seminkim/simulation-free-node">code</a>]
  </p>

  <p>
    Learning Symmetrization for Equivariance with Orbit Distance Minimization<br>
    Tien Dat Nguyen*, <u>Jinwoo Kim</u>*, Hongseok Yang, Seunghoon Hong<br>
    NeurIPS NeurReps Workshop, 2023<br>
    [<a href="https://arxiv.org/abs/2311.07143">paper</a>] [<a
      href="https://github.com/tiendatnguyen-vision/Orbit-symmetrize">code</a>] [<a
      href="https://drive.google.com/file/d/1EgGdGV_ZgQSLbuphk3NtK5FPGxAlp8au/view?usp=drive_link">poster</a>]
  </p>

  <p>
    Learning Probabilistic Symmetrization for Architecture Agnostic Equivariance<br>
    <u>Jinwoo Kim</u>, Tien Dat Nguyen, Ayhan Suleymanzade, Hyeokjun An, Seunghoon Hong<br>
    NeurIPS, 2023. <b>Spotlight (378/12345=3.06%)</b><br>
    [<a href="https://arxiv.org/abs/2306.02866">paper</a>] [<a href="https://github.com/jw9730/lps">code</a>] [<a
      href="https://drive.google.com/file/d/1sKQMzrJp79dYAx9Gqv1a63ltwrF6fRUG/view?usp=drive_link">poster</a>] [<a
      href="https://docs.google.com/presentation/d/1BpfzPXZepUKU4aNNCAf0-X5-dyy49wQPNKKkPCXiJoM/edit?usp=drive_link">slides</a>]
    [<a
      href="https://docs.google.com/presentation/d/15jGNVcWjxP5H-lXHJvpYd6yRw3fRcpbHYB0Ob6DMFIs/edit?usp=drive_link">extended
      slides</a>]
  </p>

  <p>
    Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching<br>
    Donggyun Kim, <u>Jinwoo Kim</u>, Seongwoong Cho, Chong Luo, Seunghoon Hong<br>
    ICLR, 2023. <b>Outstanding Paper Award (4/4955=0.08%)</b><br>
    Silver Prize, Samsung Humantech Paper Award, 2023<br>
    [<a href="https://arxiv.org/abs/2303.14969">paper</a>] [<a
      href="https://github.com/GitGyun/visual_token_matching">code</a>]
  </p>

  <p>
    Pure Transformers are Powerful Graph Learners<br>
    <u>Jinwoo Kim</u>, Tien Dat Nguyen, Seonwoo Min, Sungjun Cho, Moontae Lee, Honglak Lee<sup>&dagger;</sup>, Seunghoon
    Hong<sup>&dagger;</sup><br>
    NeurIPS, 2022<br>
    [<a href="https://arxiv.org/abs/2207.02505">paper</a>] [<a href="https://github.com/jw9730/tokengt">code</a>] [<a
      href="https://www.youtube.com/watch?v=TAKyjYoimd0">talk</a>] [<a
      href="https://drive.google.com/file/d/1RhvZVH7qIc78DJp5MOYsjZnt9wwujR0b/view?usp=drive_link">poster</a>] [<a
      href="https://docs.google.com/presentation/d/1v2ieNHQXqAxwDXFRU9U8GndsAeoXRrpmTwrFT1gOVXk/edit?usp=drive_link">slides</a>]
    [<a
      href="https://docs.google.com/presentation/d/1Evvro8fmjhe3GwaZarpfQz0QYuwsI-JkG2xhYqdNR_Q/edit?usp=drive_link">extended
      slides</a>]
  </p>

  <p>
    Transformers Meet Stochastic Block Models: Attention with Data-Adaptive Sparsity and Cost<br>
    Sungjun Cho, Seonwoo Min, <u>Jinwoo Kim</u>, Moontae Lee, Honglak Lee, Seunghoon Hong<br>
    NeurIPS, 2022<br>
    [<a href="https://arxiv.org/abs/2210.15541">paper</a>] [<a href="https://github.com/sc782/SBM-Transformer">code</a>]
    [<a href="https://drive.google.com/file/d/1Q2TiCd1RfpsO3ETrKcOoZs1T9LoxboH0/view?usp=drive_link">poster</a>]
  </p>

  <p>
    Equivariant Hypergraph Neural Networks<br>
    <u>Jinwoo Kim</u>, Saeyoon Oh, Sungjun Cho, Seunghoon Hong<br>
    ECCV, 2022<br>
    [<a href="https://arxiv.org/abs/2208.10428">paper</a>] [<a href="https://github.com/jw9730/ehnn">code</a>] [<a
      href="https://drive.google.com/file/d/1zle2VZnq_UWGh6dIF7tJJlxOWmbFXkwP/view?usp=drive_link">poster</a>] [<a
      href="https://docs.google.com/presentation/d/1ld9uXD5wm4y5akehKtfegswnvlTVy3bM6Vl4Jhqm79E/edit?usp=drive_link">slides</a>]
  </p>

  <p>
    Transformers Generalize DeepSets and Can be Extended to Graphs and Hypergraphs<br>
    <u>Jinwoo Kim</u>, Saeyoon Oh, Seunghoon Hong<br>
    NeurIPS, 2021<br>
    Qualcomm Innovation Fellowship Korea, 2021<br>
    [<a href="https://arxiv.org/abs/2110.14416">paper</a>] [<a href="https://github.com/jw9730/hot">code</a>] [<a
      href="https://drive.google.com/file/d/1UQuxUoqxbXuv0gy4CZWN9JKHNkba_FCZ/view?usp=drive_link">poster</a>] [<a
      href="https://docs.google.com/presentation/d/1wwZspiVFLpYIdOaU_Zo2EqokDqM3tDa7HbewIWBf2J4/edit?usp=drive_link">slides</a>]
  </p>

  <p>
    SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data<br>
    <u>Jinwoo Kim</u>*, Jaehoon Yoo*, Juho Lee, Seunghoon Hong<br>
    CVPR, 2021<br>
    [<a href="https://arxiv.org/abs/2103.15619">paper</a>] [<a href="https://github.com/jw9730/setvae">code</a>] [<a
      href="https://vllab.kaist.ac.kr/viewer/project/kim2021setvae">project</a>] [<a
      href="https://drive.google.com/file/d/1kA28QdzS5X5ifn4JnAJ60t4nlZ5scZLb/view?usp=drive_link">poster</a>] [<a
      href="https://docs.google.com/presentation/d/1Hr5IUgcHc2_apnSZXWjIfSjQiJuxvZEUjlbPW7fWlbk/edit?usp=drive_link">slides</a>]
  </p>

  <p>
    Spontaneous Retinal Waves Can Generate Long-Range Horizontal Connectivity in Visual Cortex<br>
    <u>Jinwoo Kim</u>*, Min Song*, Jaeson Jang, Se-Bum Paik<br>
    The Journal of Neuroscience 40(34), 2020<br>
    [<a href="https://www.jneurosci.org/content/40/34/6584">paper</a>]
  </p>

</body>

</html>